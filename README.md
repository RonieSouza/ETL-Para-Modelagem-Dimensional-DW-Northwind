# ETL do Banco Relacional para Dimensional (DW) - Northwind üè¢üìä

Este projeto exemplifica o processo de **ETL (Extract, Transform, Load)** para cria√ß√£o de um banco dimensional Data Warehouse (DW) a partir do banco relacional Northwind, utilizando a ferramenta **Pentaho Data Integration (PDI)**. O objetivo √© demonstrar um caso de uso simples e flex√≠vel, destacando as etapas de carga para a **staging area** e posteriormente a cria√ß√£o do **DW**.

## üöÄ Vis√£o Geral

O processo visa gerar indicadores de resultados de vendas e est√° estruturado para trabalhar com as seguintes entidades:

- **category**
- **customer**
- **employee**
- **orderdetail**
- **salesorder**
- **product**
- **shipper**
- **supplier**

### üõ†Ô∏è Etapas do Projeto

1. **Carga Inicial para Staging Area**: As tabelas relevantes do banco `northwind` s√£o extra√≠das e carregadas no banco de staging, chamado `northwind_staging`. Este banco foi criado com foco na **performance de consulta e carga**, sem relacionamentos f√≠sicos entre as tabelas.

   ![Diagrama Northwind](northwind.png)
   <p align="center"><em>Figura 1: Diagrama do banco relacional northwind.</em></p>

   ![Diagrama Northwind Staging](northwind_staging.png)
   <p align="center"><em>Figura 2: Diagrama do banco northwind_staging.</em></p>

3. **Pipeline de Carga para Staging**: O pipeline (job) abaixo mostra o processo de consulta ao banco `northwind` e carga para o banco `northwind_staging`:

   ![Pipeline Job Staging](job_staging.png)
   <p align="center"><em>Figura 3: Pipeline de carga do banco relacional northwind para staging area northwind_staging.</em></p>

4. **Transforma√ß√£o e Carga para o Data Warehouse**: Ap√≥s a carga inicial, √© realizada a transforma√ß√£o e carga para o ambiente dimensional `northwind_dw`. Esse ambiente foi modelado com foco em performance e flexibilidade futura para lidar com dimens√µes do tipo **SCD (Slowly Changing Dimension)**. No entanto, atualmente as dimens√µes s√£o atualizadas diretamente (sem hist√≥rico). As dimens√µes e fatos criados s√£o:

   - **Dimens√µes**:
     - `dim_customer`
     - `dim_date`
     - `dim_employee`
     - `dim_product`
     - `dim_shipper`
     - `dim_shipping_address`
     - `dim_supplier`
   
   - **Tabela Fato**:
     - `fact_sales`

   A integridade referencial √© mantida pelo processo de ETL, garantindo performance. Optou-se por **n√£o criar chaves estrangeiras (FK)** f√≠sicas entre fatos e dimens√µes, e a **tabela fato n√£o possui chave prim√°ria (PK)**, o que maximiza a **efici√™ncia de carga e consulta**. Ao evitar a verifica√ß√£o de chaves durante o processo de carga, o tempo de inser√ß√£o √© reduzido significativamente, o que √© crucial em cen√°rios com grandes volumes de dados.

   ![Diagrama Northwind DW](northwind_dw.png)
   <p align="center"><em>Figura 4: Diagrama do banco dimensional northwind_dw.</em></p>

6. **Pipeline de Carga para o Data Warehouse (DW)**: O pipeline (job) abaixo realiza a transforma√ß√£o e carga dos dados do ambiente `northwind_staging` para o `northwind_dw`:

   ![Pipeline Job DW](job_dw.png)
   <p align="center"><em>Figura 5: Pipeline de carga do banco staging area northwind_staging para o dw northwind_dw.</em></p>

### üåç Ambiente de Desenvolvimento

O exemplo foi desenvolvido e testado em um ambiente local, mas para ambientes de produ√ß√£o, √© **recomendado separar os ambientes** (staging e DW) do ambiente de produ√ß√£o. Essa separa√ß√£o evita que o processo de transforma√ß√£o impacte negativamente o sistema de produ√ß√£o, isolando os recursos e garantindo a integridade e a performance da aplica√ß√£o principal.

   ![Pipeline Principal de Orquestra√ß√£o](job_principal.png)
   <p align="center"><em>Figura 6: Pipeline de orquestra√ß√£o principal.</em></p>

### üìÇ Estrutura de Arquivos e Utiliza√ß√£o

Todos os arquivos necess√°rios para as transforma√ß√µes, pipelines (jobs) e o script SQL est√£o dispon√≠veis no arquivo `data_jobs_transformations.rar`. Basta extrair o conte√∫do para acessar os seguintes recursos:

- **Transforma√ß√µes e Pipelines (Jobs)**: Inclui todos os pipelines configurados para realizar as etapas de carga inicial para a staging area e o Data Warehouse, al√©m do **job principal** (`job_principal.kjb`), que orquestra todo o processo de ETL.
- **Script SQL (`dump_database_relacional_northwind.sql`)**: Respons√°vel pela cria√ß√£o do banco relacional `northwind` inicial.

> **Como utilizar**: 
> 1. Extraia o conte√∫do de `data_jobs_transformations.rar`.
> 2. Abra o Pentaho Data Integration (PDI).
> 3. Importe as transforma√ß√µes e jobs para o Pentaho Data Integration (PDI).
> 4. Para configurar as vari√°veis de ambiente, pressione `Ctrl + Alt + J` enquanto estiver na √°rea principal do Spoon. Na janela que ser√° aberta, defina os seguintes par√¢metros:
>    - `HOST_ORIGEM_MYSQL`: Host do banco de dados.
>    - `USER_ORIGEM_MYSQL`: Usu√°rio do banco de dados.
>    - `PASS_ORIGEM_MYSQL`: Senha do banco de dados.
> 5. Execute o **job principal** (`job_principal.kjb`) para automatizar a cria√ß√£o do banco relacional `northwind` e as etapas de cria√ß√£o da staging area (`northwind_staging`) e do Data Warehouse (`northwind_dw`).

> **Nota**: O job utiliza o script (`dump_database_relacional_northwind.sql`) para criar o ambiente inicial `northwind`.

### üß∞ Ferramentas Utilizadas

- **Banco de Dados**: MySQL 8.0.30
- **ETL**: Pentaho Data Integration (PDI)
- **IDE para Consultas**: DBeaver

## üìù Observa√ß√µes Finais

Este √© um exemplo b√°sico de um processo ETL utilizando o banco Northwind. Existem diversas outras abordagens e t√©cnicas que poderiam ser aplicadas dependendo das necessidades espec√≠ficas de neg√≥cio e das pol√≠ticas de integra√ß√£o e seguran√ßa do ambiente.

## üìú Licen√ßa

Este projeto √© licenciado sob a licen√ßa **MIT**, permitindo que voc√™ use, copie e modifique o software de acordo com as necessidades do seu projeto. Veja o arquivo `LICENSE` para mais detalhes.

---

¬© 2024 - Projeto de ETL Northwind DW üöÄ
